{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "hub_name = \"StarkWizard/Mistral-7b-instruct-cairo-instruct\"\n",
    "quant_name = hub_name + \"-AWQ\"\n",
    "\n",
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"StarkWizard/cairo-instruct\"\n",
    "\n",
    "quant_config = {\n",
    "    \"zero_point\":True,\n",
    "    \"q_group_size\":128,\n",
    "    \"w_bit\":4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Model and tokenizer\n",
    "\n",
    "model = AutoAWQForCausalLM.from_pretrained(hub_name,device_map=\"auto\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "AWQ: 100%|██████████| 32/32 [2:00:32<00:00, 226.01s/it]\n",
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/tokenizer_config.json',\n",
       " 'StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/special_tokens_map.json',\n",
       " 'StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/tokenizer.model',\n",
       " 'StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hub_name,trust_remote_code=True, use_auth_token=True, add_eos_token=True, use_fast=False)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token_id = 18610\n",
    "\n",
    "#quantize\n",
    "model.quantize(tokenizer=tokenizer,quant_config=quant_config)\n",
    "\n",
    "#Now we save\n",
    "model.save_quantized(quant_name, safetensors=True, shard_size=\"1GB\")\n",
    "tokenizer.save_pretrained(quant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646378f6307a4354b4378c114b58aac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/989M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e077e72b73654b26be8be9acb05063f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/907M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc56209daaf14621a9e451609e3b5609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/998M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f631d146d98544ea86479ee199fc4181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde809216bd44b8b892fd4923f625931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/994M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca1e52b273346c786a306755f225ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/262M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/tree/main/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=quant_name,\n",
    "    repo_id=quant_name,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded config.json\n",
      "Uploaded generation_config.json\n",
      "Uploaded quant_config.json\n",
      "Uploaded tokenizer_config.json\n",
      "Uploaded special_tokens_map.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Provided path: 'StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/tokenizer.json' is not a file on the local file system",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     name \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     api\u001b[39m.\u001b[39;49mupload_file(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         path_or_fileobj\u001b[39m=\u001b[39;49mf,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         path_in_repo\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         repo_id\u001b[39m=\u001b[39;49mrepo,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         repo_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pechaut/prj/cairo-llm/quantize/quantize-Mistral-7B-Instruct-Cairo.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploaded \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/huggingface_hub/hf_api.py:849\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    848\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/huggingface_hub/hf_api.py:3455\u001b[0m, in \u001b[0;36mHfApi.upload_file\u001b[0;34m(self, path_or_fileobj, path_in_repo, repo_id, token, repo_type, revision, commit_message, commit_description, create_pr, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   3450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid repo type, must be one of \u001b[39m\u001b[39m{\u001b[39;00mREPO_TYPES\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3452\u001b[0m commit_message \u001b[39m=\u001b[39m (\n\u001b[1;32m   3453\u001b[0m     commit_message \u001b[39mif\u001b[39;00m commit_message \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpload \u001b[39m\u001b[39m{\u001b[39;00mpath_in_repo\u001b[39m}\u001b[39;00m\u001b[39m with huggingface_hub\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3454\u001b[0m )\n\u001b[0;32m-> 3455\u001b[0m operation \u001b[39m=\u001b[39m CommitOperationAdd(\n\u001b[1;32m   3456\u001b[0m     path_or_fileobj\u001b[39m=\u001b[39;49mpath_or_fileobj,\n\u001b[1;32m   3457\u001b[0m     path_in_repo\u001b[39m=\u001b[39;49mpath_in_repo,\n\u001b[1;32m   3458\u001b[0m )\n\u001b[1;32m   3460\u001b[0m commit_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_commit(\n\u001b[1;32m   3461\u001b[0m     repo_id\u001b[39m=\u001b[39mrepo_id,\n\u001b[1;32m   3462\u001b[0m     repo_type\u001b[39m=\u001b[39mrepo_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3469\u001b[0m     parent_commit\u001b[39m=\u001b[39mparent_commit,\n\u001b[1;32m   3470\u001b[0m )\n\u001b[1;32m   3472\u001b[0m \u001b[39mif\u001b[39;00m commit_info\u001b[39m.\u001b[39mpr_url \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<string>:5\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, path_in_repo, path_or_fileobj)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/huggingface_hub/_commit_api.py:149\u001b[0m, in \u001b[0;36mCommitOperationAdd.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m     path_or_fileobj \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mnormpath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_or_fileobj))\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(path_or_fileobj):\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided path: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath_or_fileobj\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a file on the local file system\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_or_fileobj, (io\u001b[39m.\u001b[39mBufferedIOBase, \u001b[39mbytes\u001b[39m)):\n\u001b[1;32m    151\u001b[0m     \u001b[39m# ^^ Inspired from: https://stackoverflow.com/questions/44584829/how-to-determine-if-file-is-opened-in-binary-or-text-mode\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpath_or_fileobj must be either an instance of str, bytes or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m io.BufferedIOBase. If you passed a file-like object, make sure it is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in binary mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Provided path: 'StarkWizard/Mistral-7b-instruct-cairo-instruct-AWQ/tokenizer.json' is not a file on the local file system"
     ]
    }
   ],
   "source": [
    "#Pushing Files to HF\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "repo = quant_name\n",
    "local = \"./\"+repo+\"/\"\n",
    "files =[\n",
    "    local+\"config.json\",\n",
    "    local+\"generation_config.json\",\n",
    "    local+\"quant_config.json\",\n",
    "    local+\"tokenizer_config.json\",\n",
    "    local+\"special_tokens_map.json\",\n",
    "] \n",
    "\n",
    "for f in files:\n",
    "    name = f.split(\"/\")[-1]\n",
    "\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f,\n",
    "        path_in_repo=name,\n",
    "        repo_id=repo,\n",
    "        repo_type=\"model\",\n",
    "    )\n",
    "    print(f\"Uploaded {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= AutoAWQForCausalLM.from_quantized(quant_name,device_map=\"auto\",fuse_layers=True,\n",
    "                trust_remote_code=True,safetensors=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_name,trust_remote_code=True, use_auth_token=True, add_eos_token=True, use_fast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
