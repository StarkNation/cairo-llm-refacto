{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in VSCODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if Torch supports CUDA\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"StarkWizard/cairo-instruct\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"StarkWizard/llama-2-7b-cairo-trained-PEFT\"\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "max_steps = 700 # to tweak to get the best out of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1b635e9aaa4816bd076666540f059e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "\n",
    "# Load the tokenizer from the model (llama2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token =tokenizer.eos_token\n",
    "\n",
    "# load the quantized settings: 4 bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "\n",
    "\n",
    "# don't use the cache\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp=1\n",
    "peft_config = LoraConfig(\n",
    "        r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/datasets/load.py:2097: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002da71d27a549a9aefc7daded3ff72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e70d6bcc146a99804f1e7fd438c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee6ca83f1044031b85ad89e970d3574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76036ff30e404482affc13c47cae362e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/36.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7d74c9104d4d1fbdae0ffd40f0dffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2268d15b2f4c96ac9683f3b6fba8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a6c080b4754cb28d9df885acb593eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5e0f6f69ee4d2eb63bc720920d2e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d159d6faf971422f8629989a55372425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be44963031bf4ad9adbf3dbd0eaf0a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01498f2a5da46288d1c9cf907296e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/36.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03e11f8a4ab4b6eaa9dca81ade87bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ee0e829d5944139fa4c9163fd6d3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9bac0169a94ca5ba61e0657ea32145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset_train = load_dataset(dataset_name, split=\"train\", download_mode='force_redownload',ignore_verifications=True)\n",
    "dataset_test = load_dataset(dataset_name, split=\"eval\", download_mode='force_redownload',ignore_verifications=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if everything is fine before launching training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf8561bac094918919ce27b53b4caa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7ebbeda30e471eb5c3a2f9ccc463cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab4e9f3cb954e2a9eb41279d42d0662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:221: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "supervised_finetuning_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=False,\n",
    "    max_seq_length=512,\n",
    "    neftune_noise_alpha=5,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=3,\n",
    "        warmup_ratio=0.03,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        learning_rate=2e-4,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=1,\n",
    "        output_dir=new_model,\n",
    "        max_steps=max_steps,\n",
    "        fp16=True,\n",
    "        push_to_hub=True,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4f109b263c4db3a8bec20c53527d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5287, 'learning_rate': 0.00019995065603657316, 'epoch': 0.12}\n",
      "{'loss': 2.8018, 'learning_rate': 0.00019970908853907026, 'epoch': 0.24}\n",
      "{'loss': 2.4956, 'learning_rate': 0.00019926672020679736, 'epoch': 0.37}\n",
      "{'loss': 1.9681, 'learning_rate': 0.00019862444191070408, 'epoch': 0.49}\n",
      "{'loss': 1.8496, 'learning_rate': 0.0001977835471138027, 'epoch': 0.61}\n",
      "{'loss': 1.5734, 'learning_rate': 0.00019674572926630567, 'epoch': 0.73}\n",
      "{'loss': 1.5447, 'learning_rate': 0.0001955130783952423, 'epoch': 0.86}\n",
      "{'loss': 1.4797, 'learning_rate': 0.00019408807689542257, 'epoch': 0.98}\n",
      "{'loss': 1.4469, 'learning_rate': 0.00019247359453022407, 'epoch': 1.1}\n",
      "{'loss': 1.1731, 'learning_rate': 0.00019067288265227082, 'epoch': 1.22}\n",
      "{'loss': 1.1972, 'learning_rate': 0.0001886895676556415, 'epoch': 1.35}\n",
      "{'loss': 1.2246, 'learning_rate': 0.00018652764367279461, 'epoch': 1.47}\n",
      "{'loss': 1.2272, 'learning_rate': 0.00018419146453091701, 'epoch': 1.59}\n",
      "{'loss': 1.0996, 'learning_rate': 0.00018168573498389564, 'epoch': 1.71}\n",
      "{'loss': 1.2084, 'learning_rate': 0.00017901550123756906, 'epoch': 1.84}\n",
      "{'loss': 1.1579, 'learning_rate': 0.00017618614078734069, 'epoch': 1.96}\n",
      "{'loss': 1.1654, 'learning_rate': 0.00017320335158861855, 'epoch': 2.08}\n",
      "{'loss': 0.9852, 'learning_rate': 0.0001700731405818914, 'epoch': 2.2}\n",
      "{'loss': 1.1115, 'learning_rate': 0.00016680181159555013, 'epoch': 2.33}\n",
      "{'loss': 0.957, 'learning_rate': 0.0001633959526508162, 'epoch': 2.45}\n",
      "{'loss': 0.9669, 'learning_rate': 0.00015986242269434354, 'epoch': 2.57}\n",
      "{'loss': 0.9488, 'learning_rate': 0.00015620833778521307, 'epoch': 2.69}\n",
      "{'loss': 0.9237, 'learning_rate': 0.0001524410567641366, 'epoch': 2.82}\n",
      "{'loss': 0.9711, 'learning_rate': 0.00014856816643373083, 'epoch': 2.94}\n",
      "{'loss': 0.9318, 'learning_rate': 0.00014459746627970685, 'epoch': 3.06}\n",
      "{'loss': 0.8031, 'learning_rate': 0.0001405369527637436, 'epoch': 3.18}\n",
      "{'loss': 0.6687, 'learning_rate': 0.00013639480321967845, 'epoch': 3.31}\n",
      "{'loss': 0.8784, 'learning_rate': 0.00013217935938544497, 'epoch': 3.43}\n",
      "{'loss': 0.95, 'learning_rate': 0.00012789911060392294, 'epoch': 3.55}\n",
      "{'loss': 0.8839, 'learning_rate': 0.0001235626767265316, 'epoch': 3.67}\n",
      "{'loss': 0.805, 'learning_rate': 0.000119178790753996, 'epoch': 3.8}\n",
      "{'loss': 0.8317, 'learning_rate': 0.00011475628124924577, 'epoch': 3.92}\n",
      "{'loss': 0.7421, 'learning_rate': 0.00011030405455786425, 'epoch': 4.04}\n",
      "{'loss': 0.6759, 'learning_rate': 0.00010583107687189388, 'epoch': 4.16}\n",
      "{'loss': 0.7785, 'learning_rate': 0.00010134635617311853, 'epoch': 4.29}\n",
      "{'loss': 0.6005, 'learning_rate': 9.685892409218717e-05, 'epoch': 4.41}\n",
      "{'loss': 0.6161, 'learning_rate': 9.237781772011153e-05, 'epoch': 4.53}\n",
      "{'loss': 0.6057, 'learning_rate': 8.791206140876746e-05, 'epoch': 4.65}\n",
      "{'loss': 0.7405, 'learning_rate': 8.347064859705153e-05, 'epoch': 4.78}\n",
      "{'loss': 0.6273, 'learning_rate': 7.906252369929154e-05, 'epoch': 4.9}\n",
      "{'loss': 0.6637, 'learning_rate': 7.469656409238685e-05, 'epoch': 5.02}\n",
      "{'loss': 0.5217, 'learning_rate': 7.038156223795224e-05, 'epoch': 5.14}\n",
      "{'loss': 0.5691, 'learning_rate': 6.612620797547087e-05, 'epoch': 5.27}\n",
      "{'loss': 0.6391, 'learning_rate': 6.193907102211358e-05, 'epoch': 5.39}\n",
      "{'loss': 0.5087, 'learning_rate': 5.782858371446927e-05, 'epoch': 5.51}\n",
      "{'loss': 0.647, 'learning_rate': 5.380302402694104e-05, 'epoch': 5.63}\n",
      "{'loss': 0.5302, 'learning_rate': 4.9870498901007524e-05, 'epoch': 5.76}\n",
      "{'loss': 0.5597, 'learning_rate': 4.6417320502100316e-05, 'epoch': 5.88}\n",
      "{'loss': 0.5461, 'learning_rate': 4.268321178110779e-05, 'epoch': 6.0}\n",
      "{'loss': 0.511, 'learning_rate': 3.90645314437192e-05, 'epoch': 6.12}\n",
      "{'loss': 0.5149, 'learning_rate': 3.556856703055058e-05, 'epoch': 6.24}\n",
      "{'loss': 0.5381, 'learning_rate': 3.220235894867794e-05, 'epoch': 6.37}\n",
      "{'loss': 0.4421, 'learning_rate': 2.8972686293194308e-05, 'epoch': 6.49}\n",
      "{'loss': 0.4665, 'learning_rate': 2.5886053195014538e-05, 'epoch': 6.61}\n",
      "{'loss': 0.5017, 'learning_rate': 2.2948675722421086e-05, 'epoch': 6.73}\n",
      "{'loss': 0.5332, 'learning_rate': 2.016646936272987e-05, 'epoch': 6.86}\n",
      "{'loss': 0.3935, 'learning_rate': 1.7545037109285946e-05, 'epoch': 6.98}\n",
      "{'loss': 0.4903, 'learning_rate': 1.5089658177780653e-05, 'epoch': 7.1}\n",
      "{'loss': 0.5068, 'learning_rate': 1.2805277374613744e-05, 'epoch': 7.22}\n",
      "{'loss': 0.4359, 'learning_rate': 1.069649513871147e-05, 'epoch': 7.35}\n",
      "{'loss': 0.3851, 'learning_rate': 8.767558276854549e-06, 'epoch': 7.47}\n",
      "{'loss': 0.4449, 'learning_rate': 7.022351411174866e-06, 'epoch': 7.59}\n",
      "{'loss': 0.403, 'learning_rate': 5.464389156043115e-06, 'epoch': 7.71}\n",
      "{'loss': 0.3939, 'learning_rate': 4.096809040103444e-06, 'epoch': 7.84}\n",
      "{'loss': 0.3907, 'learning_rate': 2.922365187708187e-06, 'epoch': 7.96}\n",
      "{'loss': 0.4322, 'learning_rate': 1.9434227724779984e-06, 'epoch': 8.08}\n",
      "{'loss': 0.3791, 'learning_rate': 1.1619532541569333e-06, 'epoch': 8.2}\n",
      "{'loss': 0.3982, 'learning_rate': 5.795304083548559e-07, 'epoch': 8.33}\n",
      "{'loss': 0.4012, 'learning_rate': 1.973271571728441e-07, 'epoch': 8.45}\n",
      "{'loss': 0.4812, 'learning_rate': 1.6113207094181626e-08, 'epoch': 8.57}\n",
      "{'train_runtime': 2017.6403, 'train_samples_per_second': 1.041, 'train_steps_per_second': 0.347, 'train_loss': 0.8824873300961086, 'epoch': 8.57}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=0.8824873300961086, metrics={'train_runtime': 2017.6403, 'train_samples_per_second': 1.041, 'train_steps_per_second': 0.347, 'train_loss': 0.8824873300961086, 'epoch': 8.57})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_finetuning_trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are on a colab, push to hub or save to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae1b56c49d54d999de10542578f2140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/StarkWizard/llama-2-7b-cairo-trained/commit/25f029151b1a42870258fcbb251d62be7e0e42ad', commit_message='Upload model', commit_description='', oid='25f029151b1a42870258fcbb251d62be7e0e42ad', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_finetuning_trainer.model.push_to_hub(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
