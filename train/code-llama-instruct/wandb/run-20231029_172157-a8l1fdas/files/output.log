/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/datasets/load.py:2097: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.
You can remove this warning by passing 'verification_mode=no_checks' instead.
  warnings.warn(
You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.9551, 'learning_rate': 0.0001998167734774926, 'epoch': 0.06}
{'eval_loss': 1.8411781787872314, 'eval_runtime': 0.9721, 'eval_samples_per_second': 5.143, 'eval_steps_per_second': 1.029, 'epoch': 0.06}
{'loss': 1.4562, 'learning_rate': 0.00019918425982253334, 'epoch': 0.13}
{'eval_loss': 1.706878662109375, 'eval_runtime': 1.0198, 'eval_samples_per_second': 4.903, 'eval_steps_per_second': 0.981, 'epoch': 0.13}
{'loss': 1.3708, 'learning_rate': 0.0001981030576540612, 'epoch': 0.19}
{'eval_loss': 1.709925889968872, 'eval_runtime': 0.9371, 'eval_samples_per_second': 5.335, 'eval_steps_per_second': 1.067, 'epoch': 0.19}
{'loss': 1.3326, 'learning_rate': 0.000196578058100917, 'epoch': 0.26}
{'eval_loss': 1.6518948078155518, 'eval_runtime': 0.9376, 'eval_samples_per_second': 5.333, 'eval_steps_per_second': 1.067, 'epoch': 0.26}
{'loss': 1.3333, 'learning_rate': 0.0001946161599369973, 'epoch': 0.32}
{'eval_loss': 1.6765550374984741, 'eval_runtime': 0.9675, 'eval_samples_per_second': 5.168, 'eval_steps_per_second': 1.034, 'epoch': 0.32}
{'loss': 1.2625, 'learning_rate': 0.0001922262383726672, 'epoch': 0.38}
{'eval_loss': 1.5847467184066772, 'eval_runtime': 0.9836, 'eval_samples_per_second': 5.083, 'eval_steps_per_second': 1.017, 'epoch': 0.38}
{'loss': 1.2584, 'learning_rate': 0.0001894191049051948, 'epoch': 0.45}
{'eval_loss': 1.5900769233703613, 'eval_runtime': 1.0173, 'eval_samples_per_second': 4.915, 'eval_steps_per_second': 0.983, 'epoch': 0.45}
{'loss': 1.2415, 'learning_rate': 0.0001862074584098352, 'epoch': 0.51}
{'eval_loss': 1.6267772912979126, 'eval_runtime': 1.0308, 'eval_samples_per_second': 4.851, 'eval_steps_per_second': 0.97, 'epoch': 0.51}
{'loss': 1.2212, 'learning_rate': 0.00018260582769281743, 'epoch': 0.58}
{'eval_loss': 1.554892897605896, 'eval_runtime': 1.0519, 'eval_samples_per_second': 4.753, 'eval_steps_per_second': 0.951, 'epoch': 0.58}
{'loss': 1.2199, 'learning_rate': 0.00017863050576611265, 'epoch': 0.64}
{'eval_loss': 1.5303624868392944, 'eval_runtime': 0.9833, 'eval_samples_per_second': 5.085, 'eval_steps_per_second': 1.017, 'epoch': 0.64}
{'loss': 1.2258, 'learning_rate': 0.0001742994761413105, 'epoch': 0.71}
{'eval_loss': 1.542641520500183, 'eval_runtime': 0.9685, 'eval_samples_per_second': 5.162, 'eval_steps_per_second': 1.032, 'epoch': 0.71}
{'loss': 1.183, 'learning_rate': 0.0001696323314760344, 'epoch': 0.77}
{'eval_loss': 1.4965219497680664, 'eval_runtime': 1.0325, 'eval_samples_per_second': 4.843, 'eval_steps_per_second': 0.969, 'epoch': 0.77}
{'loss': 1.192, 'learning_rate': 0.0001646501849409221, 'epoch': 0.83}
{'eval_loss': 1.4172214269638062, 'eval_runtime': 1.0455, 'eval_samples_per_second': 4.782, 'eval_steps_per_second': 0.956, 'epoch': 0.83}
{'loss': 1.1582, 'learning_rate': 0.0001593755747081285, 'epoch': 0.9}
{'eval_loss': 1.4447803497314453, 'eval_runtime': 0.9886, 'eval_samples_per_second': 5.058, 'eval_steps_per_second': 1.012, 'epoch': 0.9}
{'loss': 1.1599, 'learning_rate': 0.00015383236199342467, 'epoch': 0.96}
{'eval_loss': 1.4466129541397095, 'eval_runtime': 1.0343, 'eval_samples_per_second': 4.834, 'eval_steps_per_second': 0.967, 'epoch': 0.96}
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1123, 'learning_rate': 0.00014804562311312828, 'epoch': 1.03}
{'eval_loss': 1.4344122409820557, 'eval_runtime': 0.959, 'eval_samples_per_second': 5.214, 'eval_steps_per_second': 1.043, 'epoch': 1.03}
{'loss': 0.9782, 'learning_rate': 0.00014204153604417775, 'epoch': 1.09}
{'eval_loss': 1.3840891122817993, 'eval_runtime': 1.0048, 'eval_samples_per_second': 4.976, 'eval_steps_per_second': 0.995, 'epoch': 1.09}
{'loss': 1.0229, 'learning_rate': 0.00013584726200052767, 'epoch': 1.15}
{'eval_loss': 1.3403971195220947, 'eval_runtime': 0.9908, 'eval_samples_per_second': 5.046, 'eval_steps_per_second': 1.009, 'epoch': 1.15}
{'loss': 0.9689, 'learning_rate': 0.00012949082256158905, 'epoch': 1.22}
{'eval_loss': 1.353610873222351, 'eval_runtime': 1.0378, 'eval_samples_per_second': 4.818, 'eval_steps_per_second': 0.964, 'epoch': 1.22}
{'loss': 0.9935, 'learning_rate': 0.00012300097290855887, 'epoch': 1.28}
{'eval_loss': 1.3480857610702515, 'eval_runtime': 1.0165, 'eval_samples_per_second': 4.919, 'eval_steps_per_second': 0.984, 'epoch': 1.28}
{'loss': 0.9962, 'learning_rate': 0.00011640707174209147, 'epoch': 1.35}
{'eval_loss': 1.3364070653915405, 'eval_runtime': 0.966, 'eval_samples_per_second': 5.176, 'eval_steps_per_second': 1.035, 'epoch': 1.35}
{'loss': 0.9497, 'learning_rate': 0.00010973894846977548, 'epoch': 1.41}
{'eval_loss': 1.3273981809616089, 'eval_runtime': 0.9536, 'eval_samples_per_second': 5.244, 'eval_steps_per_second': 1.049, 'epoch': 1.41}
{'loss': 0.929, 'learning_rate': 0.00010302676826423338, 'epoch': 1.47}
{'eval_loss': 1.3291481733322144, 'eval_runtime': 0.9198, 'eval_samples_per_second': 5.436, 'eval_steps_per_second': 1.087, 'epoch': 1.47}
{'loss': 0.9838, 'learning_rate': 9.630089560229088e-05, 'epoch': 1.54}
{'eval_loss': 1.3194364309310913, 'eval_runtime': 1.0038, 'eval_samples_per_second': 4.981, 'eval_steps_per_second': 0.996, 'epoch': 1.54}
{'loss': 0.9444, 'learning_rate': 8.95917569025366e-05, 'epoch': 1.6}
{'eval_loss': 1.3165539503097534, 'eval_runtime': 0.9986, 'eval_samples_per_second': 5.007, 'eval_steps_per_second': 1.001, 'epoch': 1.6}
{'loss': 0.9403, 'learning_rate': 8.292970288267042e-05, 'epoch': 1.67}
{'eval_loss': 1.3257337808609009, 'eval_runtime': 1.0091, 'eval_samples_per_second': 4.955, 'eval_steps_per_second': 0.991, 'epoch': 1.67}
{'loss': 0.9507, 'learning_rate': 7.634487125930648e-05, 'epoch': 1.73}
{'eval_loss': 1.328719139099121, 'eval_runtime': 0.9752, 'eval_samples_per_second': 5.127, 'eval_steps_per_second': 1.025, 'epoch': 1.73}
{'loss': 0.9549, 'learning_rate': 6.986705041134796e-05, 'epoch': 1.79}
{'eval_loss': 1.336380958557129, 'eval_runtime': 1.0209, 'eval_samples_per_second': 4.898, 'eval_steps_per_second': 0.98, 'epoch': 1.79}
{'loss': 0.9442, 'learning_rate': 6.352554462369112e-05, 'epoch': 1.86}
{'eval_loss': 1.3326457738876343, 'eval_runtime': 0.9509, 'eval_samples_per_second': 5.258, 'eval_steps_per_second': 1.052, 'epoch': 1.86}
{'loss': 0.9046, 'learning_rate': 5.734904152086828e-05, 'epoch': 1.92}
{'eval_loss': 1.3327916860580444, 'eval_runtime': 0.9757, 'eval_samples_per_second': 5.125, 'eval_steps_per_second': 1.025, 'epoch': 1.92}
{'loss': 0.9351, 'learning_rate': 5.1365482290330645e-05, 'epoch': 1.99}
{'eval_loss': 1.333182692527771, 'eval_runtime': 0.9932, 'eval_samples_per_second': 5.034, 'eval_steps_per_second': 1.007, 'epoch': 1.99}
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.8019, 'learning_rate': 4.560193528245425e-05, 'epoch': 2.05}
{'eval_loss': 1.3577911853790283, 'eval_runtime': 0.9529, 'eval_samples_per_second': 5.247, 'eval_steps_per_second': 1.049, 'epoch': 2.05}
{'loss': 0.7719, 'learning_rate': 4.0084473559075333e-05, 'epoch': 2.12}
{'eval_loss': 1.3536839485168457, 'eval_runtime': 0.9585, 'eval_samples_per_second': 5.217, 'eval_steps_per_second': 1.043, 'epoch': 2.12}
{'loss': 0.7458, 'learning_rate': 3.483805694449913e-05, 'epoch': 2.18}
{'eval_loss': 1.353284478187561, 'eval_runtime': 1.0335, 'eval_samples_per_second': 4.838, 'eval_steps_per_second': 0.968, 'epoch': 2.18}
{'loss': 0.74, 'learning_rate': 2.9886419112559394e-05, 'epoch': 2.24}
{'eval_loss': 1.3459835052490234, 'eval_runtime': 1.0345, 'eval_samples_per_second': 4.833, 'eval_steps_per_second': 0.967, 'epoch': 2.24}
{'loss': 0.7309, 'learning_rate': 2.525196022052142e-05, 'epoch': 2.31}
{'eval_loss': 1.3297061920166016, 'eval_runtime': 0.9451, 'eval_samples_per_second': 5.291, 'eval_steps_per_second': 1.058, 'epoch': 2.31}
{'loss': 0.7599, 'learning_rate': 2.0955645575531003e-05, 'epoch': 2.37}
{'eval_loss': 1.3273320198059082, 'eval_runtime': 1.0102, 'eval_samples_per_second': 4.95, 'eval_steps_per_second': 0.99, 'epoch': 2.37}
{'loss': 0.7361, 'learning_rate': 1.701691079202019e-05, 'epoch': 2.44}
{'eval_loss': 1.3233397006988525, 'eval_runtime': 0.965, 'eval_samples_per_second': 5.182, 'eval_steps_per_second': 1.036, 'epoch': 2.44}
{'loss': 0.7315, 'learning_rate': 1.3453573869118097e-05, 'epoch': 2.5}
{'eval_loss': 1.3172383308410645, 'eval_runtime': 0.9612, 'eval_samples_per_second': 5.202, 'eval_steps_per_second': 1.04, 'epoch': 2.5}
{'loss': 0.7388, 'learning_rate': 1.0281754585809178e-05, 'epoch': 2.56}
{'eval_loss': 1.3196134567260742, 'eval_runtime': 0.9531, 'eval_samples_per_second': 5.246, 'eval_steps_per_second': 1.049, 'epoch': 2.56}
{'loss': 0.7457, 'learning_rate': 7.5158015784790315e-06, 'epoch': 2.63}
{'eval_loss': 1.3246569633483887, 'eval_runtime': 1.0254, 'eval_samples_per_second': 4.876, 'eval_steps_per_second': 0.975, 'epoch': 2.63}
{'loss': 0.7416, 'learning_rate': 5.168227430732353e-06, 'epoch': 2.69}
{'eval_loss': 1.320656180381775, 'eval_runtime': 1.013, 'eval_samples_per_second': 4.936, 'eval_steps_per_second': 0.987, 'epoch': 2.69}
{'loss': 0.7624, 'learning_rate': 3.249652069124032e-06, 'epoch': 2.76}
{'eval_loss': 1.3203861713409424, 'eval_runtime': 0.9408, 'eval_samples_per_second': 5.315, 'eval_steps_per_second': 1.063, 'epoch': 2.76}
{'loss': 0.7114, 'learning_rate': 1.7687547208681598e-06, 'epoch': 2.82}
{'eval_loss': 1.3214106559753418, 'eval_runtime': 0.9686, 'eval_samples_per_second': 5.162, 'eval_steps_per_second': 1.032, 'epoch': 2.82}
{'loss': 0.7019, 'learning_rate': 7.322346508586209e-07, 'epoch': 2.88}
{'eval_loss': 1.3215241432189941, 'eval_runtime': 1.0158, 'eval_samples_per_second': 4.922, 'eval_steps_per_second': 0.984, 'epoch': 2.88}
{'loss': 0.7122, 'learning_rate': 1.4478085561835386e-07, 'epoch': 2.95}
{'eval_loss': 1.3215906620025635, 'eval_runtime': 0.9738, 'eval_samples_per_second': 5.134, 'eval_steps_per_second': 1.027, 'epoch': 2.95}
{'train_runtime': 7223.048, 'train_samples_per_second': 1.295, 'train_steps_per_second': 0.324, 'train_loss': 1.0002470554449618, 'epoch': 3.0}
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
