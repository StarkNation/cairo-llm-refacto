
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/datasets/load.py:2097: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.
You can remove this warning by passing 'verification_mode=no_checks' instead.
  warnings.warn(
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:183: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024
  warnings.warn(
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:226: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 3.9176, 'learning_rate': 1.993114384372975e-05, 'epoch': 0.12}
{'eval_loss': 3.3322510719299316, 'eval_runtime': 1.1187, 'eval_samples_per_second': 4.469, 'eval_steps_per_second': 0.894, 'epoch': 0.12}
{'loss': 2.5813, 'learning_rate': 1.9694339696585942e-05, 'epoch': 0.25}
{'eval_loss': 2.9762418270111084, 'eval_runtime': 1.0882, 'eval_samples_per_second': 4.595, 'eval_steps_per_second': 0.919, 'epoch': 0.25}
{'loss': 2.2759, 'learning_rate': 1.929276146260306e-05, 'epoch': 0.37}
{'eval_loss': 2.43976092338562, 'eval_runtime': 1.0143, 'eval_samples_per_second': 4.93, 'eval_steps_per_second': 0.986, 'epoch': 0.37}
{'loss': 1.9833, 'learning_rate': 1.8733234741963262e-05, 'epoch': 0.5}
{'eval_loss': 2.2481772899627686, 'eval_runtime': 1.0866, 'eval_samples_per_second': 4.602, 'eval_steps_per_second': 0.92, 'epoch': 0.5}
{'loss': 1.8403, 'learning_rate': 1.802526977541951e-05, 'epoch': 0.62}
{'eval_loss': 2.107473850250244, 'eval_runtime': 1.0261, 'eval_samples_per_second': 4.873, 'eval_steps_per_second': 0.975, 'epoch': 0.62}
{'loss': 1.6999, 'learning_rate': 1.7180899799326968e-05, 'epoch': 0.74}
{'eval_loss': 2.0070340633392334, 'eval_runtime': 1.0996, 'eval_samples_per_second': 4.547, 'eval_steps_per_second': 0.909, 'epoch': 0.74}
{'loss': 1.5187, 'learning_rate': 1.6214476517475636e-05, 'epoch': 0.87}
{'eval_loss': 1.8367398977279663, 'eval_runtime': 1.0681, 'eval_samples_per_second': 4.681, 'eval_steps_per_second': 0.936, 'epoch': 0.87}
{'loss': 1.3952, 'learning_rate': 1.5142426166076644e-05, 'epoch': 0.99}
{'eval_loss': 1.7963680028915405, 'eval_runtime': 0.9965, 'eval_samples_per_second': 5.018, 'eval_steps_per_second': 1.004, 'epoch': 0.99}
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.3404, 'learning_rate': 1.3982970318050471e-05, 'epoch': 1.12}
{'eval_loss': 1.7200286388397217, 'eval_runtime': 1.0305, 'eval_samples_per_second': 4.852, 'eval_steps_per_second': 0.97, 'epoch': 1.12}
{'loss': 1.2952, 'learning_rate': 1.2755816172089164e-05, 'epoch': 1.24}
{'eval_loss': 1.6555883884429932, 'eval_runtime': 1.0985, 'eval_samples_per_second': 4.551, 'eval_steps_per_second': 0.91, 'epoch': 1.24}
{'loss': 1.292, 'learning_rate': 1.1481821590629984e-05, 'epoch': 1.36}
{'eval_loss': 1.660041093826294, 'eval_runtime': 1.0782, 'eval_samples_per_second': 4.637, 'eval_steps_per_second': 0.927, 'epoch': 1.36}
{'loss': 1.2547, 'learning_rate': 1.0182640580069249e-05, 'epoch': 1.49}
{'eval_loss': 1.598638653755188, 'eval_runtime': 1.0891, 'eval_samples_per_second': 4.591, 'eval_steps_per_second': 0.918, 'epoch': 1.49}
{'loss': 1.2256, 'learning_rate': 8.880355238966923e-06, 'epoch': 1.61}
{'eval_loss': 1.5672248601913452, 'eval_runtime': 1.0651, 'eval_samples_per_second': 4.694, 'eval_steps_per_second': 0.939, 'epoch': 1.61}
{'loss': 1.2464, 'learning_rate': 7.597100429995461e-06, 'epoch': 1.73}
{'eval_loss': 1.5793023109436035, 'eval_runtime': 1.0384, 'eval_samples_per_second': 4.815, 'eval_steps_per_second': 0.963, 'epoch': 1.73}
{'loss': 1.216, 'learning_rate': 6.354687555060303e-06, 'epoch': 1.86}
{'eval_loss': 1.5899643898010254, 'eval_runtime': 1.0393, 'eval_samples_per_second': 4.811, 'eval_steps_per_second': 0.962, 'epoch': 1.86}
{'loss': 1.1889, 'learning_rate': 5.174233828262855e-06, 'epoch': 1.98}
{'eval_loss': 1.569914698600769, 'eval_runtime': 1.0876, 'eval_samples_per_second': 4.597, 'eval_steps_per_second': 0.919, 'epoch': 1.98}
/home/pechaut/miniconda3/envs/cairo-llm/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1494, 'learning_rate': 4.075803347930245e-06, 'epoch': 2.11}
{'eval_loss': 1.5493152141571045, 'eval_runtime': 1.0423, 'eval_samples_per_second': 4.797, 'eval_steps_per_second': 0.959, 'epoch': 2.11}
{'loss': 1.1279, 'learning_rate': 3.0780660683881625e-06, 'epoch': 2.23}
{'eval_loss': 1.5586141347885132, 'eval_runtime': 1.1004, 'eval_samples_per_second': 4.544, 'eval_steps_per_second': 0.909, 'epoch': 2.23}
{'loss': 1.1415, 'learning_rate': 2.1979804679123108e-06, 'epoch': 2.35}
{'eval_loss': 1.548916220664978, 'eval_runtime': 1.0845, 'eval_samples_per_second': 4.611, 'eval_steps_per_second': 0.922, 'epoch': 2.35}
{'loss': 1.1566, 'learning_rate': 1.4505053065314612e-06, 'epoch': 2.48}
{'eval_loss': 1.5443440675735474, 'eval_runtime': 0.9798, 'eval_samples_per_second': 5.103, 'eval_steps_per_second': 1.021, 'epoch': 2.48}
{'loss': 1.143, 'learning_rate': 8.483453729167623e-07, 'epoch': 2.6}
{'eval_loss': 1.5394967794418335, 'eval_runtime': 1.0381, 'eval_samples_per_second': 4.817, 'eval_steps_per_second': 0.963, 'epoch': 2.6}
{'loss': 1.1344, 'learning_rate': 4.0173554188154273e-07, 'epoch': 2.73}
{'eval_loss': 1.5391888618469238, 'eval_runtime': 1.0463, 'eval_samples_per_second': 4.779, 'eval_steps_per_second': 0.956, 'epoch': 2.73}
{'loss': 1.1182, 'learning_rate': 1.182668128528286e-07, 'epoch': 2.85}
{'eval_loss': 1.538561224937439, 'eval_runtime': 1.0593, 'eval_samples_per_second': 4.72, 'eval_steps_per_second': 0.944, 'epoch': 2.85}
{'loss': 1.1438, 'learning_rate': 2.7572861278046813e-09, 'epoch': 2.97}
{'eval_loss': 1.538438320159912, 'eval_runtime': 1.0759, 'eval_samples_per_second': 4.647, 'eval_steps_per_second': 0.929, 'epoch': 2.97}
